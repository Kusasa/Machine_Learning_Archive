{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcwLKuQXCLkA"
   },
   "source": [
    "# Akeed Restaurant Recommendation Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IX4DwGh_MMGr"
   },
   "source": [
    "## Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yysxbPuCT8A"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import psycopg2\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from shapely.geometry import Point\n",
    "from copy import deepcopy, copy\n",
    "import multiprocessing as mp\n",
    "from pathos.multiprocessing import ProcessingPool as Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def currentSecondsTime():\n",
    "    \"\"\" Returns the current time in seconds\"\"\"\n",
    "    return int(time.time())\n",
    "\n",
    "\n",
    "def timeTaken(startTime, endTime):\n",
    "    \"\"\" Returns the difference between a start time and an end time\n",
    "        formatted as 00:00:00 \"\"\"\n",
    "    timeTaken = endTime - startTime\n",
    "    return str(datetime.timedelta(seconds=timeTaken))\n",
    "\n",
    "def showPyMessage(message, messageType=\"Message\"):\n",
    "    \"\"\" Shows a formatted message to the user during processing. \"\"\"\n",
    "    if (messageType == \"Message\"):\n",
    "        os.system('echo ' + str(time.ctime()) + \" - \" + message + \"'\")\n",
    "        print(message)\n",
    "    if (messageType == \"Warning\"):\n",
    "        os.system('echo ' + str(time.ctime()) + \" - \" + message + \"'\")\n",
    "        print(message)\n",
    "    if (messageType == \"Error\"):\n",
    "        os.system('echo ' + str(time.ctime()) + \" - \" + message + \"'\")\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the base layers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Postgis Layer\n",
    "#con = psycopg2.connect(host=\"localhost\", database=\"vulcan\", port=\"6666\", user=\"tebogo\", password=\"tebogo\")\n",
    "#countries_sql = \"SELECT * FROM public.countries WHERE cntry_name = 'Oman'\"\n",
    "#countries_gdf = gpd.GeoDataFrame.from_postgis(countries_sql, con, geom_col='geom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytBzPY1hBu9t"
   },
   "outputs": [],
   "source": [
    "#Training Locations\n",
    "training_locations = pd.read_csv(\"./train_locations.csv\")\n",
    "print(\"\\n This table has \" + str(len(training_locations)) + \" rows.\")\n",
    "training_locations.head()\n",
    "#training_locations.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Customers\n",
    "training_customers = pd.read_csv(\"./train_customers.csv\")\n",
    "print(\"\\n This table has \" + str(len(training_customers)) + \" rows.\")\n",
    "training_customers.head()\n",
    "#training_customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufe3SE81CVZB"
   },
   "source": [
    "### Base Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Orders\n",
    "orders = pd.read_csv(\"./orders.csv\")\n",
    "print(\"\\n This table has \" + str(len(orders)) + \" rows.\")\n",
    "orders.head()\n",
    "#orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vendors\n",
    "vendors = pd.read_csv(\"./vendors.csv\")\n",
    "print(\"\\n This table has \" + str(len(vendors)) + \" rows.\")\n",
    "vendors.head()\n",
    "#vendors.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process tables where need be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = currentSecondsTime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add valuable calculated fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add geometry field to the training locations table\n",
    "geometry = [Point(xy) for xy in zip(training_locations.longitude, training_locations.latitude)]\n",
    "crs = {'init': 'epsg:4326'} #crs assumed\n",
    "training_locations_gdf = gpd.GeoDataFrame(training_locations, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add geometry field to the vendors table\n",
    "geometry = [Point(xy) for xy in zip(vendors.longitude, vendors.latitude)]\n",
    "crs = {'init': 'epsg:4326'} #crs assumed\n",
    "vendors_gdf = gpd.GeoDataFrame(vendors, crs=crs, geometry=geometry)\n",
    "vendors_gdf.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose focus training table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduce reference columns in orders table\n",
    "training_table = deepcopy(orders)\n",
    "\n",
    "def func(training_table):\n",
    "    for index, row in training_table.iterrows():\n",
    "        training_table.loc[index, \"customer_id\"] = training_table[\"CID X LOC_NUM X VENDOR\"][index].split(\" X \")[0]\n",
    "        training_table.loc[index, \"location_number\"] = training_table[\"CID X LOC_NUM X VENDOR\"][index].split(\" X \")[1]\n",
    "        training_table.loc[index, \"vendor_id\"] = training_table[\"CID X LOC_NUM X VENDOR\"][index].split(\" X \")[2]\n",
    "\n",
    "cores=mp.cpu_count()\n",
    "\n",
    "df_split = np.array_split(training_table, cores, axis=0)\n",
    "\n",
    "# create the multiprocessing pool\n",
    "pool = Pool(cores)\n",
    "\n",
    "# process the DataFrame by mapping function to each df across the pool\n",
    "df_out = np.vstack(pool.map(func, df_split))\n",
    "\n",
    "# close down the pool and join\n",
    "pool.close()\n",
    "pool.join()\n",
    "pool.clear()\n",
    "\n",
    "training_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge training locations and training customers\n",
    "training_customers= training_customers.rename({'akeed_customer_id': 'customer_id'}, axis=1)\n",
    "compiled_training_customers = pd.merge(training_locations_gdf, training_customers, on ='customer_id', how ='right')\n",
    "compiled_training_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge compiled training customers to the training table\n",
    "training_table = pd.merge(training_table, compiled_training_customers, on ='customer_id', how ='left')\n",
    "training_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge vendors to the training table\n",
    "vendors = vendors.rename({'id': 'vendor_id'}, axis=1)\n",
    "vendors[\"vendor_id\"]= vendors[\"vendor_id\"].astype(str)\n",
    "training_table[\"vendor_id\"]= training_table[\"vendor_id\"].astype(str)\n",
    "training_table = pd.merge(training_table, vendors, on ='vendor_id', how ='left')\n",
    "training_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_table = training_table.fillna(value=\"unknown\")\n",
    "#training_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with mixed data-type fields in training table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find mixed data type columns\n",
    "'''for col in training_table.columns:\n",
    "    weird = (training_table[[col]].applymap(type) != training_table[[col]].iloc[0].apply(type)).any(axis=1)\n",
    "    if len(training_table[weird]) > 0:\n",
    "        print(col)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode nominal fields in training table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location Type column\n",
    "dummy = pd.get_dummies(training_table['location_type'])\n",
    "encoded_training_table = training_table.merge(dummy, left_index=True, right_index=True)\n",
    "encoded_training_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender column\n",
    "encoded_training_table['gender'] = encoded_training_table['gender'].str.upper()\n",
    "encoded_training_table['gender'] = encoded_training_table['gender'].str.strip()\n",
    "dummy = pd.get_dummies(encoded_training_table['gender'])\n",
    "encoded_training_table = encoded_training_table.merge(dummy, left_index=True, right_index=True)\n",
    "encoded_training_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scale field values if need be, in training table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = StandardScaler()\n",
    "#scaled_X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the vendor_id column of the training table as the y variable then encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating training table into x and y (y being vendor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the y set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime = currentSecondsTime()\n",
    "showPyMessage(\" -- Preprocessing done. Took {}\".format(timeTaken(startTime, endTime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFVqP4NhCaFK"
   },
   "source": [
    "## Exploring Relationships using plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "A4pNfzNhCKlc",
    "outputId": "06f57e4d-db5f-4df3-80ee-c79d6d0d5e9e"
   },
   "outputs": [],
   "source": [
    "#Spatial Relations\n",
    "\n",
    "ax = encoded_training_table.plot(color = 'grey', figsize = (18, 12), legend=True)\n",
    "#countries_gdf.plot(ax=ax, edgecolor = 'grey', facecolor = 'none')\n",
    "#ax.set(xlim=(15, 35), ylim=(-37.5, -20))\n",
    "ax.set_axis_off()\n",
    "plt.title(label = 'Customers & Vendors Locations', fontweight = 'bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "nsxVbZ6rDoZu"
   },
   "outputs": [],
   "source": [
    "# Linear Relations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsEWyt7_KGW0"
   },
   "source": [
    "## Prediction Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baggxvxMLmC_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Game Count Starter Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
